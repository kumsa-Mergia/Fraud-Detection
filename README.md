# ğŸ›¡ï¸ Fraud Detection Project

This project aims to detect fraudulent transactions using **machine learning** and **explainable AI**. It supports both **e-commerce fraud detection** and **credit card fraud detection** using a modular and test-driven workflow.

The pipeline covers:

* Data preprocessing
* Exploratory Data Analysis (EDA)
* Model training and evaluation
* Explainability using SHAP

---

## ğŸ“ Project Structure

```bash
Fraud-Detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw datasets (Fraud_Data.csv, creditcard.csv, IpAddress_to_Country.csv)
â”‚   â”œâ”€â”€ processed/                  # Cleaned and feature-engineered datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda/                        # EDA notebooks
â”‚   â”‚   â”œâ”€â”€ 01_eda_fraud.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_eda_credit.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_eda_balanced_fraud_data.ipynb
â”‚   â”œâ”€â”€ model_training/            # Model training notebooks
â”‚   â”‚   â”œâ”€â”€ creditcard_model_training.ipynb
â”‚   â”‚   â”œâ”€â”€ fraud_model_training.ipynb
â”‚   â”‚   â”œâ”€â”€ balanced_fraud_data_model_training.ipynb
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ explainability/            # SHAP and model interpretability
â”‚   â”‚   â””â”€â”€XGBoost_explainability.ipynb
â”‚   â”‚   â””â”€â”€RandomForest_explainability.ipynb.ipynb
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ data_processing.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_preprocessor.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base_model.py
â”‚   â”‚   â”œâ”€â”€ logistic_model.py
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”‚   â”œâ”€â”€ ensemble_model.py
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ shap_explainer.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ip_to_int.py
â”‚   â”œâ”€â”€ test_load_data.py
â”‚   â”œâ”€â”€ test_logistic_model.py
â”‚   â”œâ”€â”€ test_xgboost_model.py
â”‚
â”œâ”€â”€ requirements.txt               # Python package dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ .gitignore                     # Files and folders to exclude from Git
```

---

## ğŸ§ª Features

* ğŸ§¹ Clean and preprocess raw data from multiple sources
* ğŸ“Š Perform in-depth **EDA** for insight extraction
* ğŸ§  Train & evaluate multiple ML models:

  * Logistic Regression
  * XGBoost
  * Random Forest
* ğŸ¯ Evaluate models using F1 Score, AUC-PR, and Confusion Matrix
* ğŸ” Use **SHAP** for interpretability and explainability
* ğŸ§ª Includes unit tests for critical components
* ğŸ“¦ Modular structure (ideal for CI/CD and production deployment)

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/kumsa-Mergia/Fraud-Detection.git
cd Fraud-Detection
```

2. **Create and activate a virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Add raw data**

Place raw datasets in the `data/raw/` directory:

* `Fraud_Data.csv`
* `creditcard.csv`
* `IpAddress_to_Country.csv`

---

## ğŸš€ How to Use

### ğŸ“Š 1. Explore the Data

Run the EDA notebooks in:

```bash
notebooks/eda/
```

### ğŸ§  2. Train Models

Open and run the training notebooks:

```bash
notebooks/model_training/
```

Includes:

* Evaluation metrics (F1, AUC-PR)
* Confusion matrices
* Model comparison

### ğŸ” 3. Explain Predictions

Run SHAP-based explainability in:

```bash
notebooks/explainability/model_explainability.ipynb
```

### âœ… 4. Run Unit Tests

```bash
pytest tests/
```

---

## ğŸ§  Model Performance Highlights

| Dataset     | Model         | AUC-PR | F1 Score | Accuracy |
| ----------- | ------------- | ------ | -------- | -------- |
| Credit Card | Logistic      | 0.6877 | 0.0996   | 97.0%    |
|             | XGBoost       | 0.8036 | 0.8333   | 99.9%    |
|             | Random Forest | 0.8196 | 0.8178   | 99.9%    |
| Fraud       | Logistic      | 0.4522 | 0.2682   | 64.0%    |
|             | XGBoost       | 0.5967 | 0.6699   | 95.0%    |
|             | Random Forest | 0.6208 | 0.6951   | 96.0%    |

---

## ğŸ“Š SHAP Explainability

This project uses SHAP (SHapley Additive exPlanations) to visualize:

* Global feature importance
* Local instance-based explanations
* Feature effects on predictions

---

## ğŸ“Œ Notes

* ğŸ“‚ Raw datasets are excluded due to privacy and size constraints.
* ğŸ Python 3.8+ is recommended.
* â˜‘ï¸ Project follows a modular and testable architecture for scalability and reproducibility.

---

## ğŸ‘¨â€ğŸ’» Author

**Kumsa Mergia**
ğŸ“« [kumsa-mergia.github.io](https://github.com/kumsa-Mergia)

---